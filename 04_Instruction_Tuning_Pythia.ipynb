{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahabday/DSR-LLM-finetuning/blob/main/04_Instruction_Tuning_Pythia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTHEF1YsB7f6"
      },
      "outputs": [],
      "source": [
        "# Adapted from https://www.danliden.com/fine-tuning/4_olmo_1b_instruction_tune/4_olmo_instruction_tune.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfM9l85AFLpR",
        "outputId": "44bef191-3ea3-4907-e429-44aed353e8cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
            "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
            "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors>=0.4.3 (from accelerate)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm>=4.66.3 (from datasets)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting transformers (from peft)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from trl)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
            "  Downloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
            "Collecting regex!=2019.12.17 (from transformers->peft)\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers->peft)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->trl)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from rich->trl) (2.17.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/micromamba/envs/python_310/lib/python3.10/site-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m146.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: pytz, xxhash, tzdata, tqdm, safetensors, requests, regex, pyarrow, propcache, multidict, mdurl, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, markdown-it-py, huggingface-hub, aiosignal, tokenizers, rich, bitsandbytes, aiohttp, accelerate, transformers, peft, datasets, trl\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "Successfully installed accelerate-1.4.0 aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.1.0 bitsandbytes-0.45.3 datasets-3.3.2 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.1 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 peft-0.14.0 propcache-0.3.0 pyarrow-19.0.1 pytz-2025.1 regex-2024.11.6 requests-2.32.3 rich-13.9.4 safetensors-0.5.3 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.49.0 trl-0.15.2 tzdata-2025.1 xxhash-3.5.0 yarl-1.18.3\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate datasets peft trl bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c2526b7d-9ca8-444a-85a9-a176eb33ff29",
          "showTitle": false,
          "title": ""
        },
        "id": "zP_gR9u5EosB"
      },
      "outputs": [],
      "source": [
        "# Some Environment Setup\n",
        "OUTPUT_DIR = \"./results/pythia/\" # the path to the output directory; where model checkpoints will be saved\n",
        "LOG_DIR = \"./logs/pythia/\" # the path to the log directory; where logs will be saved\n",
        "CACHE_DIR = \"./cache/pythia/\" # the path to the cache directory; where cache files will be saved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-ULRfYwEosB"
      },
      "source": [
        "## Loading Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b47f3426-08a6-49af-b14d-ed582e1e1a03",
          "showTitle": true,
          "title": "Model Loading and Initialization"
        },
        "id": "T0A4WKdQEosC"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_ckpt = \"EleutherAI/pythia-410m\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_ckpt,\n",
        ")\n",
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_ckpt,\n",
        "    device_map='cuda:0'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "20a2b2d8-19a2-40e1-ac1b-e45cd90eb2d3",
          "showTitle": false,
          "title": ""
        },
        "id": "dG0Bi5TxEosE"
      },
      "source": [
        "### Prompting Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqYEwOMzB7gC"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "def generate(prompt, max_new_tokens=100):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "    gen_tokens = model.generate(input_ids,\n",
        "                                max_new_tokens=max_new_tokens,\n",
        "                                eos_token_id=tokenizer.eos_token_id,\n",
        "                                repetition_penalty=1.1)\n",
        "    return tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a146a775-dcff-4844-8767-1629c4b7b18e",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt-EDKEREosE",
        "outputId": "acf8457f-5fd9-44d5-d4cf-e4bba5ed53e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are step-by-step instructions to make a great cup of coffee with a Chemex coffee maker:\n",
            "1. Add the water and coffee grounds to the coffee pot.\n",
            "2. Fill the coffee pot with hot water, then add the ground coffee beans.\n",
            "3. Pour in the milk and stir until it is fully mixed.\n",
            "4. Add the sugar and stir again.\n",
            "5. Add the espresso powder and stir again.\n",
            "6. Add the cream and stir again.\n",
            "7. Add the vanilla extract and stir again.\n",
            "8. Add the coffee liqueur and stir again\n"
          ]
        }
      ],
      "source": [
        "print(generate(\"Here are step-by-step instructions to make a great cup of coffee with a Chemex coffee maker:\\n1.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45NEFc9_B7gE",
        "outputId": "a3aa002c-46f8-4661-9c12-a501b337e2de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are step-by-step instructions to make a Margarita drink:\n",
            "1. Fill a glass with ice and add 1/2 cup of water.\n",
            "2. Add the juice from one lime, one grapefruit, one orange, one kiwi, one pineapple, one mango, one banana, one apple, one cantaloupe, one papaya, one pineapple, one watermelon, one pineapple, one grapefruit, one orange, one kiwi, one pineapple, one mango, one banana, one apple, one cantaloupe,\n"
          ]
        }
      ],
      "source": [
        "print(generate(\"Here are step-by-step instructions to make a Margarita drink:\\n1.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6d887b85-bdcd-4752-a579-f932e2138ae4",
          "showTitle": false,
          "title": ""
        },
        "id": "AWj3xoioEosG"
      },
      "source": [
        "What happens if, instead, we ask a question or give an instruction? As the model has not been instruction tuned, these will not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5709d467-28b5-48a6-92f3-fa7c5e09b55a",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn9EPS1qEosH",
        "outputId": "ab9bca09-3c0b-4c2c-a1c6-e538a587e747"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How do I make coffee with a Chemex coffee maker?\n",
            "\n",
            "I have been using the Chemex for about 2 years now and it has become my go to machine. It is very easy to use, you just need to fill up your cup with water and then add in the coffee grounds. The only thing that I would like to say is that if you are not familiar with the Chemex, you should definitely check out their website. They have a great selection of machines and they even have a free trial version.\n",
            "\n",
            "What is the best way\n"
          ]
        }
      ],
      "source": [
        "# Question\n",
        "print(generate(\"How do I make coffee with a Chemex coffee maker?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "24e59d5f-ef82-4cfb-b2ae-5c5bdfa2044b",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6tnAJbiEosJ",
        "outputId": "3d0f9595-7f7f-43a9-e0fc-162a30fd4d50"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tell me how to make coffee with a Chemex coffee maker.\n",
            "\n",
            "I have been using the Chemex for about 2 years now and I love it! It is very easy to use, you just need to fill up your cup with water and then add in some ground coffee. The only thing that I would change is that I would like to be able to add more ground coffee than what is listed on the box. I am not sure if this is possible but I will try my best to find out.\n",
            "\n",
            "I have been using the Chemex for\n"
          ]
        }
      ],
      "source": [
        "# Instruction\n",
        "print(generate(\"Tell me how to make coffee with a Chemex coffee maker.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlS5jj5TB7gI",
        "outputId": "070f974f-2340-478a-d9a5-de984d44379a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tell me how to make a Margarita drink.\n",
            "\n",
            "I'm not sure what I was thinking, but it didn't work out so well for me. I had no idea that the only way to get a margarita is to have a glass of water and then pour in some ice. It's like drinking a soda without any sugar.\n",
            "\n",
            "So I decided to try something different. I took a sip of my water and poured in some ice cubes. Then I added a little bit more water and let it sit for a few seconds\n"
          ]
        }
      ],
      "source": [
        "print(generate(\"Tell me how to make a Margarita drink.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "b845dc87-6319-4f33-a3c9-0da15ea165b3",
          "showTitle": false,
          "title": ""
        },
        "id": "q2mOdT8gEosK"
      },
      "source": [
        "These did not work because the model has not been instruction tuned.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We'll be using the [SlimOrca](https://huggingface.co/datasets/Open-Orca/SlimOrca) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "38515af3-6113-4550-8726-f32e46a0b65d",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "a2185edc9b614af786f81d4efd11d878",
            "793cb4504eb149f5ba6103bf29e582de",
            "5c4bc915efe44678be50432007d9c6ad",
            "e34f9e0457b04293a84cf6b9563e9345",
            "feceed7c3f57463dacf2858174a35cc4",
            "f69d3343f97f4def9be945519391c445",
            "c10c10979eb74a6387b035e8ffcbd030",
            "a04030dc8c9d49959e8e5631edfc6d5f",
            "d4c97278aac84263abecbe0ce5dfeeff",
            "96967d9ec45941bfaf1d22bac18b2ef2",
            "c33baee068cd4ff0b521223bf4f4d404",
            "65ff521eba10495692b41f085ec33fec",
            "336ab53cd34e48f3b6e934cfac4cd1c8",
            "7e2a7b9468254fe1ae49557fe2726b79",
            "6e7256e81ffe491da8ea45bd10987702",
            "94d990a792fb47b995b16a67a32c526e",
            "063c222cfc944ea2946a27479669e8cc",
            "d9f1a0c5761548b4a2d542d3b981b8ac",
            "82e93bf1ad3e45d692d45f25bfd2f0f9",
            "47976a62313842309661edc78b8716a9",
            "b36601341dfa495aaa0217115d00aeab",
            "73552c210a6f4b01a10fbd666a3ce60f",
            "436ead45746b422c864dc6b70b224b6b",
            "b4e13b79919d41d2b8ac4a2cddc191e8",
            "966f01d289fb4842bf94e5019b095dfa",
            "773c73bfb5d644448b069ee04ec4df52",
            "8bb05a19de9c4a91903efb37e00aaa2d",
            "01b37e205f194345991a759b50c7b6df",
            "6dab287bf20c4b0e9d36bd3a5aaec195",
            "4ebaaffbe04049b59d947a75f2d1084c",
            "bf7e2bd696464a818a0a7d53bc67254e",
            "3aeb1159631249bf9fa76439e7f8808a",
            "1e3c330124684ed7be73e0020ec28db4",
            "ee0a5f1a5b41412daca5c717935ecaea",
            "41a1c38eadea4f95a0e2a49b5c0d4825",
            "61ecf95f0d2446eeb33efd65a85ae5af",
            "52ffb2f3d29e48d386655dd0bf09ed08",
            "824a00aa352f4541b162e647943734d3",
            "593e04a22b3c4b5eb772211948b14c66",
            "b8e896879377470287d0cb410959511b",
            "c48bef9d985d40ce82769813b9621aa1",
            "c30e74a63cbe4f97b079a3879ad9ab73",
            "0b5f283c540243e685a8c4d5499ca931",
            "054c4d2d30bf4055bc0fa71f08b23377",
            "7bc24f4a197e401c846e507239629fa4",
            "2ead0736c1794e588e0dc54f1aa1b02e",
            "2ab12622fc594f3d995f22e362b9b212",
            "2adce43ac4bc47a88f03d4d84e469aa9",
            "a0d1d1a655944cd7b18372acf023144f",
            "14ad75440da64e99b2f053c8168cf8b5",
            "dbcf08370a6647fe9838927c6cb3f3ad",
            "42d7c9cd742349dc9d7d3f6f0b13c224",
            "68e8503f954b4c4c8861401d80b022bf",
            "93d4b356373d40e78e81131367a01e72",
            "2f986cd5c1d64ba788eeef3653fcbef0",
            "d681cfffe6fa45e3922d59be84e80783",
            "493c10db43eb432bb32f00793c1d8ebc",
            "eb722054866a4158ac98e141d03485d0",
            "6a1b9ad18f1448ebbcd39d866337f954",
            "31172abb798a428cbc4d9a3e79eaa230"
          ]
        },
        "id": "6SdC4eR1EosL",
        "outputId": "da303a25-37f6-460a-e4d9-fcd087c583b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d681cfffe6fa45e3922d59be84e80783",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/2.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "493c10db43eb432bb32f00793c1d8ebc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dataset_infos.json:   0%|          | 0.00/653 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb722054866a4158ac98e141d03485d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00002-6d275f30fa8e143f.parquet:   0%|          | 0.00/163M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a1b9ad18f1448ebbcd39d866337f954",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00001-of-00002-20da825e60baa022.parquet:   0%|          | 0.00/145M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31172abb798a428cbc4d9a3e79eaa230",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/363491 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from pathlib import Path\n",
        "\n",
        "slimorca = load_dataset('Open-Orca/SlimOrca-Dedup',\n",
        "                           cache_dir=str(Path(CACHE_DIR) / \"data\"), split='train')\n",
        "slimorca = slimorca.shuffle(seed=42).select(range(11000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0fe430a4-b83d-425e-9a17-9f8513d07df8",
          "showTitle": false,
          "title": ""
        },
        "id": "5xmJ32JMEosL"
      },
      "source": [
        "Here's one record from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6e762f9f-cde0-40e4-9f96-5bfb979456fd",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdnrt1iaEosM",
        "outputId": "d5a269ff-9d82-440b-eb30-660cef6fa8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"conversations\": [\n",
            "        {\n",
            "            \"from\": \"system\",\n",
            "            \"value\": \"You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.\"\n",
            "        },\n",
            "        {\n",
            "            \"from\": \"human\",\n",
            "            \"value\": \"Give the step-by-step reasoning process and then the final answer. A pen and pencil have a total cost of $6. If the pen costs twice as much as the pencil, what is the cost of the pen?\"\n",
            "        },\n",
            "        {\n",
            "            \"from\": \"gpt\",\n",
            "            \"value\": \"Step 1: Let's assign variables to the unknowns. Let's say the cost of the pencil is x dollars and the cost of the pen is y dollars.\\n\\nStep 2: We know the total cost of the pen and pencil is $6. So, we can write the equation:\\nx + y = 6\\n\\nStep 3: We also know that the pen costs twice as much as the pencil. So, we can write the equation:\\ny = 2x\\n\\nStep 4: Now, we have a system of two linear equations with two variables. We can solve this system by substitution. Since we know that y = 2x, we can substitute 2x for y in the first equation:\\nx + 2x = 6\\n\\nStep 5: Combine the like terms:\\n3x = 6\\n\\nStep 6: Divide both sides of the equation by 3 to solve for x:\\nx = 2\\n\\nStep 7: Now that we know the cost of the pencil (x), we can find the cost of the pen (y) using the equation y = 2x:\\ny = 2 * 2\\n\\nStep 8: Calculate the value of y:\\ny = 4\\n\\nSo, the cost of the pen is $4.\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "print(json.dumps(slimorca[0], indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "6f1c0e6e-730d-46f6-9d04-ad02710ca401",
          "showTitle": false,
          "title": ""
        },
        "id": "iNljtRdiEosM"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "We format the data using ChatML template:\n",
        "- It uses `<|im_start|>` and `<|im_end|>` special tokens\n",
        "- the template did not, by default, add an `<|endoftext|>` token at the end of the chat, so we needed to do this manually. Without training on data including the `<|endoftext|>` token, at inference time, the model just keeps generating until it hits the token limit instead of stopping naturally after addressing the instruction.\n",
        "\n",
        "#### Examine the chat template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ec6a1b0d-cc0e-40ea-96d7-9f306040687c",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YGg58jtEosM",
        "outputId": "1a5ab5c6-8f43-495c-adb4-44b52e844382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.chat_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4238ba27-9179-4864-b2c0-1172b1df0db2",
          "showTitle": false,
          "title": ""
        },
        "id": "jG0mVTAHEosM"
      },
      "source": [
        "There is no chat template defined for this tokenizer, so we'll use the default, which is the [ChatML](https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/ai-services/openai/includes/chat-markup-language.md) format. In order to use the template, we first need to adjust the slimorca records to match the following format, with `role` and `content` instead of `from` and `value` keys, and `system`/`assistant`/`user` roles instead of `system`/`gpt`/`human`. The chat is still structured as a list of dictionaries. Here's an example of a chat in the expected format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "ebd6d125-3811-465a-b6cc-8211e0a08c26",
          "showTitle": false,
          "title": ""
        },
        "id": "HttYrGc8EosO"
      },
      "outputs": [],
      "source": [
        "chat = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant and an expert at making coffee.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How do I make coffee with a Chemex coffee maker?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"To make coffee with a Chemex:\\n1. Boil water to about 200°F (93°C).\\n2. Place the Chemex filter in the top and rinse it with hot water to remove paper taste and warm the vessel. Discard the rinse water.\\n3. Add coffee grounds to the filter. Use a medium-coarse grind, about 1 gram of coffee per 16 grams of water.\\n4. Pour just enough hot water to saturate the grounds. Wait 30 seconds for the coffee to 'bloom'.\\n5. Slowly pour the remaining water over the grounds in a circular motion. Aim for a total brew time of 3.5 to 4.5 minutes.\\n6. Once brewing is complete, remove the filter and enjoy.\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "99cf4b61-4027-483d-8394-34e868916ba4",
          "showTitle": false,
          "title": ""
        },
        "id": "DZ9-v52tEosO"
      },
      "source": [
        "Now we can apply the chat template and obtain a string-formatted chat that we can tokenize and train on. Note the lack of a token indicating the end of the string! We will need to add the `tokenizer.eos_token` to the end of the string manually. This tokenizer did not define a `bos_token`, so we will proceed without one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAfRtgET-EVO"
      },
      "outputs": [],
      "source": [
        "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "19efb2b5-03a0-4593-88d5-6406f352fae2",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2WEtub3EosP",
        "outputId": "12d4bf12-5724-4107-dd7d-3bcb7b7babce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant and an expert at making coffee.<|im_end|>\n",
            "<|im_start|>user\n",
            "How do I make coffee with a Chemex coffee maker?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "To make coffee with a Chemex:\n",
            "1. Boil water to about 200°F (93°C).\n",
            "2. Place the Chemex filter in the top and rinse it with hot water to remove paper taste and warm the vessel. Discard the rinse water.\n",
            "3. Add coffee grounds to the filter. Use a medium-coarse grind, about 1 gram of coffee per 16 grams of water.\n",
            "4. Pour just enough hot water to saturate the grounds. Wait 30 seconds for the coffee to 'bloom'.\n",
            "5. Slowly pour the remaining water over the grounds in a circular motion. Aim for a total brew time of 3.5 to 4.5 minutes.\n",
            "6. Once brewing is complete, remove the filter and enjoy.<|im_end|>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "d164cc52-4900-4429-af99-698176c77242",
          "showTitle": false,
          "title": ""
        },
        "id": "eDocWGb2EosP"
      },
      "source": [
        "#### Apply the template to the whole dataset\n",
        "\n",
        "Now we need to apply the template to the whole slimorca dataset. We will first convert the slimorca entries into the expected format, and then use `tokenizer.apply_chat_template` to apply the template.\n",
        "\n",
        "We will also add the `<|im_start|>` and `<|im_end|>` special tokens to the tokenizer. The `<|endoftext|>` and `<|padding|>` tokens are already in the tokenizer's vocabulary, so we do not need to add them manually.\n",
        "\n",
        "We add the `tokenizer.eos_token` to the end of the string here. Without doing so, the model does not learn when to stop generating."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "f6d4e43d-a1bf-41c3-8fe8-d4996f4181ff",
          "showTitle": true,
          "title": "Tokenize SLIMORCA Conversations"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "46e63ff18e0f42a59cf01f23bf22ce0a",
            "73684289388743c292cf1f536641fb89",
            "81e468bf13c64391a748b112691936f5",
            "8f74e472c7bc4382b813f7c4d2444a40",
            "0130970e878f48fba3bf4e361ee9883e",
            "3f010f62faed4d03b5617f540f216aeb",
            "d187b4ed87e54d6981ded5e64ad2caf1",
            "8c344e31557f4d688fcfcbfb58790457",
            "aaf91255f75441cbb3586ebaadcf3017",
            "77e6fa69d6734bb9be4924fefe829a3f",
            "caf4d30296a84cacac5432ee72f41013",
            "7f4f9f2078704dba9341efae296e747e"
          ]
        },
        "id": "HFyA_6BQEosP",
        "outputId": "d081a851-1c70-47e4-993c-a85ea58bd387"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f4f9f2078704dba9341efae296e747e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=16):   0%|          | 0/11000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Add the instruction tokens to the tokenizer\n",
        "special_tokens = [\"<|im_start|>\", \"<|im_end|>\"]\n",
        "# Adding special tokens to the tokenizer\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
        "\n",
        "# Do not need to resize the model's input token embeddings matrix\n",
        "# it is already larger than the vocabulary/large enough to accommodate\n",
        "# the added tokens\n",
        "# model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "system_msg = \"You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.\"\n",
        "\n",
        "def format_slimorca(ex):\n",
        "    role_mapping = {\"gpt\": \"assistant\", \"system\": \"system\", \"human\": \"user\"}\n",
        "    chat = [\n",
        "        {\"role\": role_mapping[message[\"from\"]], \"content\": message[\"value\"] if message[\"from\"] != \"system\" else system_msg}\n",
        "        for message in ex[\"conversations\"]\n",
        "    ]\n",
        "    formatted_chat = tokenizer.apply_chat_template(\n",
        "        chat,\n",
        "        tokenize=False,              # Apply formatting but do not tokenize\n",
        "        add_generation_prompt=False,\n",
        "    ) + tokenizer.eos_token          # add the end of sequence token\n",
        "\n",
        "    # Tokenize using the standard tokenizer method\n",
        "    tokenized_output = tokenizer(\n",
        "        formatted_chat,\n",
        "        add_special_tokens=False,  # apply_chat_template already added special tokens\n",
        "        #padding=\"max_length\",     # pad to the specified length\n",
        "        max_length=512,            # max length at which to truncate or to which to pad\n",
        "        truncation=True,           # truncate to the specified length\n",
        "    )\n",
        "\n",
        "    return tokenized_output\n",
        "\n",
        "\n",
        "# Map to the dataset\n",
        "slimorca_tokenized = slimorca.map(format_slimorca, num_proc=16).remove_columns(\n",
        "    \"conversations\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "a5596ff0-8aa7-48c5-8c61-d8a0582fb172",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRwsHPaVEosQ",
        "outputId": "06dd837e-0db8-4541-91cb-ad54831e1af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 11000\n",
              "})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slimorca_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "c575fde4-62af-4b8d-bd12-ac9981f8bc2c",
          "showTitle": false,
          "title": ""
        },
        "id": "1yx5UVHtEosQ"
      },
      "source": [
        "Now let's inspect a single example and make sure it corresponds to the format we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "0fce41a8-3289-40e1-a70f-23a22c5e9714",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfFlrFQ4EosQ",
        "outputId": "404406a8-8a18-48e8-e96d-db20c8ddc34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.<|im_end|>\n",
            "<|im_start|>user\n",
            "How do you say \"For more info please contact us.\" in Spanish?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "To translate the phrase \"For more info please contact us.\" into Spanish, I will follow these steps:\n",
            "\n",
            "1. Identify the main ideas in the English phrase: \"more info\", \"please contact\", and \"us\".\n",
            "2. Translate each main idea into Spanish: \"más información\" (more info), \"por favor, póngase en contacto\" (please contact), and \"con nosotros\" (with us).\n",
            "3. Combine the translations to form the Spanish phrase: \"Para más información, por favor, póngase en contacto con nosotros.\"\n",
            "\n",
            "So, the translated phrase in Spanish is: \"Para más información, por favor, póngase en contacto con nosotros.\"<|im_end|>\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "# Inspect one example\n",
        "print(tokenizer.decode(slimorca_tokenized[11]['input_ids']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4b1e1f02-1e32-4145-97df-9b683bdea801",
          "showTitle": false,
          "title": ""
        },
        "id": "GTnJ2Q73EosQ"
      },
      "source": [
        "Note the padding tokens at the end. The whole example was shorter than 512 tokens, so it was padded to reach 512 tokens.\n",
        "\n",
        "#### Split the dataset into training and validation\n",
        "\n",
        "Here we also limit to a training subset of 10,000 examples. This is based on the [LIMIT](https://www.databricks.com/blog/limit-less-more-instruction-tuning) paper, which found that a small number of high-quality examples is sufficient for instruction-tuning. Under ideal circumstances, we would choose more *domain-specific* examples with a variety of different formats. Given that we are not tailoring this fine-tuning job for a specific domain, we will just choose 10,000 random examples from the SlimOrca dataset. We could almost certainly get by with fewer examples, especially if those examples were selected for quality and tailored to the specific tasks we want the model to succeed at."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "af93c8b3-fd06-4032-a17e-6be9382c505d",
          "showTitle": false,
          "title": ""
        },
        "id": "lYW4Ef7qEosR"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "from transformers import set_seed\n",
        "\n",
        "set_seed(123)\n",
        "\n",
        "slimorca_tokenized_split = slimorca_tokenized.train_test_split(\n",
        "    train_size=10000, test_size=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3d83bb55-deea-493c-a73c-1b47a0ca276f",
          "showTitle": false,
          "title": ""
        },
        "id": "D_Al4V3gEosS"
      },
      "source": [
        "Now we will configure a *collator*. The collator is responsible for taking inputs, generating labels, and assembling the inputs into batches.\n",
        "\n",
        "Since we already padded/truncated the inputs to the same lengths, we don't need anything special here. The `DataCollatorForLanguageModeling` collator will add labels to each entry. Importantly, the labels are the same as the inputs. The trainer handles shifting the labels; we do not need to implement any custom logic to align the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "5d9c337c-de67-42d1-8728-9b3c4dd64c74",
          "showTitle": false,
          "title": ""
        },
        "id": "WkT6o00cEosS"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "46b76522-bc8f-49cc-9b42-52d0b38d53fc",
          "showTitle": false,
          "title": ""
        },
        "id": "l5bGxc_sEosS"
      },
      "source": [
        "## Fine-tune the model\n",
        "\n",
        "Now that the data are ready, we can train the model using the Hugging Face `Trainer`.\n",
        "\n",
        "### Hyperparameters and Training Arguments\n",
        "At a high level: this is a fairly naive fine-tuning job. We aren't trying to excel at a specific benchmark or task. Our main goal is simply equipping the model with the ability to respond to instructions and questions in an appropriate format. We attain this goal fairly easily with a variety of different hyperparameter configurations. That said, especially when training on a smaller subset of the data for multiple epochs, the results were fairly sensitive to learning rate. The default of `0.00005` was too high and resulted in overfitting.\n",
        "- We set `auto_find_batch_size` to `True`. The trainer will try multiple batch sizes, starting from the specified `per_device_train_batch_size`, and reduce the batch size if it encounters an OOM error.\n",
        "- We use gradient accumulation to simulate a larger batch size. Gradients are accumulated over multiple mini-batches of data (because we cannot use a very large batch size). The weights are only updated after the specified number of gradient accumulation steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9aa3f56c-53cb-4f40-831a-d92f66fdd9b8",
          "showTitle": true,
          "title": "MLflow Training with Transformers"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2qNMhWwEosT",
        "outputId": "7c390eb4-182c-49ea-d5a0-05d076d19a59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/micromamba/envs/python_310/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Define the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=32,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_eval_batch_size=4,\n",
        "    auto_find_batch_size=True,\n",
        "    warmup_steps=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=LOG_DIR,\n",
        "    logging_steps=5,  # Log every 5 steps\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=20,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    gradient_checkpointing=False,\n",
        "    save_steps=100,\n",
        "    learning_rate=1e-3,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    report_to='none'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XRxH-DXCabG",
        "outputId": "68eff51c-4d13-465d-97c0-97b415e09bb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HytQJrEtB7gT"
      },
      "source": [
        "### LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ea7f461a7e754718b5d9848a8e10ba29",
            "b3d0e0b42a08494e9884347231e278a2",
            "b307ee547a8643b0a2f9eb546fafaccc",
            "b84e3d8ad8b6444382326e90dbd08205",
            "37d8976db6204c1791e37e2188e50b4e",
            "36bc7ee5fd0b4b788cf40b6636bc5107"
          ]
        },
        "id": "vYgqSVzcVr4Y",
        "outputId": "2032f7b7-5c49-4f96-c61c-ac8e2e5661c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/micromamba/envs/python_310/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea7f461a7e754718b5d9848a8e10ba29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Converting train dataset to ChatML:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3d0e0b42a08494e9884347231e278a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b307ee547a8643b0a2f9eb546fafaccc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b84e3d8ad8b6444382326e90dbd08205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Converting eval dataset to ChatML:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37d8976db6204c1791e37e2188e50b4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36bc7ee5fd0b4b788cf40b6636bc5107",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Truncating eval dataset:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=slimorca_tokenized_split[\"train\"],\n",
        "    eval_dataset=slimorca_tokenized_split[\"test\"],\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1StV94jZH4fP",
        "outputId": "22ba59c8-38e4-4f15-be72-c15443798c5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPTNeoXForCausalLM(\n",
              "  (gpt_neox): GPTNeoXModel(\n",
              "    (embed_in): Embedding(50304, 1024)\n",
              "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x GPTNeoXLayer(\n",
              "        (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
              "        (attention): GPTNeoXAttention(\n",
              "          (query_key_value): lora.Linear(\n",
              "            (base_layer): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=3072, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (dense): lora.Linear(\n",
              "            (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "        )\n",
              "        (mlp): GPTNeoXMLP(\n",
              "          (dense_h_to_4h): lora.Linear(\n",
              "            (base_layer): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=1024, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (dense_4h_to_h): lora.Linear(\n",
              "            (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (default): Dropout(p=0.05, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    (rotary_emb): GPTNeoXRotaryEmbedding()\n",
              "  )\n",
              "  (embed_out): Linear(in_features=1024, out_features=50304, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GVKB4V8RtSm",
        "outputId": "1900f61d-5e0c-4569-d2d5-a70bdf3daa54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 6291456 || all params: 411625472 || trainable%: 1.5284418550268921\n"
          ]
        }
      ],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )\n",
        "\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "fz_zYRnHDO2z",
        "outputId": "914763e8-a95f-4bc1-d7ae-83e11032d0f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [780/780 36:18, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.000400</td>\n",
              "      <td>1.888377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.829500</td>\n",
              "      <td>1.787210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.741100</td>\n",
              "      <td>1.727435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.718900</td>\n",
              "      <td>1.692388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.769600</td>\n",
              "      <td>1.668160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>1.653097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.666900</td>\n",
              "      <td>1.649694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.626600</td>\n",
              "      <td>1.645966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.596700</td>\n",
              "      <td>1.632689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.644800</td>\n",
              "      <td>1.625056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.626300</td>\n",
              "      <td>1.620766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.595700</td>\n",
              "      <td>1.614832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.572200</td>\n",
              "      <td>1.610786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.599700</td>\n",
              "      <td>1.605799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.521500</td>\n",
              "      <td>1.599166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.459700</td>\n",
              "      <td>1.618485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.448200</td>\n",
              "      <td>1.618939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.428800</td>\n",
              "      <td>1.616830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.421600</td>\n",
              "      <td>1.613708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.477300</td>\n",
              "      <td>1.612074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.435000</td>\n",
              "      <td>1.608667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.448900</td>\n",
              "      <td>1.607776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.490400</td>\n",
              "      <td>1.604305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.304100</td>\n",
              "      <td>1.630336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.380700</td>\n",
              "      <td>1.637942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.291400</td>\n",
              "      <td>1.635357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.304400</td>\n",
              "      <td>1.638192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.330100</td>\n",
              "      <td>1.636616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.334400</td>\n",
              "      <td>1.633613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.352100</td>\n",
              "      <td>1.632554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.371900</td>\n",
              "      <td>1.628539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.219500</td>\n",
              "      <td>1.662231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.234800</td>\n",
              "      <td>1.665112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.193900</td>\n",
              "      <td>1.666980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.249500</td>\n",
              "      <td>1.664892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>1.215200</td>\n",
              "      <td>1.663681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>1.251200</td>\n",
              "      <td>1.666200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>1.212600</td>\n",
              "      <td>1.663797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>1.212100</td>\n",
              "      <td>1.664121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=780, training_loss=1.4832097065754426, metrics={'train_runtime': 2180.8463, 'train_samples_per_second': 22.927, 'train_steps_per_second': 0.358, 'total_flos': 5.39774043659305e+16, 'train_loss': 1.4832097065754426})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsMFzt2OB7gV",
        "outputId": "5673764b-759f-4469-e948-725deb11ce72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./results/pythia/'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jw3AP4BDfXS"
      },
      "outputs": [],
      "source": [
        "model_ckpt = OUTPUT_DIR + \"/stop\"\n",
        "\n",
        "trainer.save_model(model_ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "893a9b35-95c8-4656-9300-eeb3adf2be4b",
          "showTitle": false,
          "title": ""
        },
        "id": "3h4tkokDEosT"
      },
      "source": [
        "## Reload the Fine-Tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTRWMT51CKnF",
        "outputId": "37475091-1cfe-4005-d147-48252d35a35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DbfK8yus5T4zYQxcAxFivwmn2pNdrnjF\n",
            "To: /workspace/pythia_instruct.zip\n",
            "100%|██████████████████████████████████████| 24.0M/24.0M [00:00<00:00, 82.1MB/s]\n",
            "Archive:  pythia_instruct.zip\n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/README.md  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/adapter_config.json  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/adapter_model.safetensors  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/special_tokens_map.json  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/tokenizer.json  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/tokenizer_config.json  \n",
            "  inflating: ./results/pythia/stop/results/pythia/stop/training_args.bin  \n"
          ]
        }
      ],
      "source": [
        "!gdown 1DbfK8yus5T4zYQxcAxFivwmn2pNdrnjF\n",
        "!unzip pythia_instruct.zip -d./results/pythia/stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmGDyU-PRZaq"
      },
      "outputs": [],
      "source": [
        "model_ckpt = OUTPUT_DIR + \"/stop\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_ckpt\n",
        ")\n",
        "tokenizer.add_special_tokens({'pad_token': '<|pad|>'})\n",
        "special_tokens = [\"<|im_start|>\", \"<|im_end|>\"]\n",
        "tokenizer.add_special_tokens({\"additional_special_tokens\": special_tokens})\n",
        "tokenizer.chat_template = \"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\n",
        "\n",
        "fine_tuned_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_ckpt,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "3Nt2owx7D-NQ",
        "outputId": "5731e6c1-6680-4e7e-e85d-6cf462a285f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXv9ZfuNRfUh"
      },
      "outputs": [],
      "source": [
        "def generate(model, tokenizer, prompt, max_new_tokens=100, chat=True):\n",
        "    if chat:\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": system_msg\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "        formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    else:\n",
        "        formatted_prompt = prompt\n",
        "\n",
        "    input_ids = tokenizer(formatted_prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
        "    model.eval()\n",
        "    gen_tokens = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        repetition_penalty=1.1,\n",
        "    )\n",
        "    return tokenizer.batch_decode(gen_tokens, skip_special_tokens=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw-fbUnQX6iA",
        "outputId": "f281047d-79b8-42c1-ef84-19da644ae1e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.<|im_end|>\n",
            "<|im_start|>user\n",
            "Tell me how to make coffee with a Chemex coffee maker.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "To create a delicious cup of coffee, it's essential to follow these simple steps:\n",
            "\n",
            "1. Preparing the grounds: Before brewing, it's crucial to thoroughly clean your Chemex coffee maker using hot water or a soft cloth. This ensures a smooth process and prevents any dirt from entering the machine.\n",
            "\n",
            "2. Setting up the temperature: Once the grounds have been cleaned and dried, set the temperature of the grounds in the Chemex coffee maker to between 200 and 250 degrees (80-110°F). This allows for optimal extraction of coffee beans, ensuring a rich flavor and a pleasant aroma.\n",
            "\n",
            "3. Brewing the coffee: Pouring the grounds into the Chemex coffee maker's brewing chamber, ensure that they are evenly distributed and well-spaced. This ensures a smooth brew and maximizes the amount of time required for the process.\n",
            "\n",
            "4. Checking the coffee quality: After brewing, check the quality of the coffee by observing the color, taste, and aroma of the brewed coffee. If there are any changes in the flavor or quality, it is advisable to adjust the brewing time or use other methods such as steaming or filtering to further improve the flavor.\n",
            "\n",
            "5. Serving the coffee: Place the coffee grounds in a large stainless steel bowl or mug, making sure not to disturb the grounds too much. Pour the coffee into the Chemex coffee maker and allow it to steep for at least one hour. This will allow the grounds to absorb the steam and infuse the coffee flavor throughout the brewing process.\n",
            "\n",
            "6. Filtering the coffee: After the steeping period, carefully pour the filtered coffee into a filter holder and let it sit for at least five minutes before serving. This ensures a smooth and even coffee flavor and reduces the chances of unwanted impurities.\n",
            "\n",
            "In summary, the Chemex coffee maker is essential for creating a delicious cup of coffee with a powerful extractor and brewing method. Using a gentle setting on the temperature and careful distribution of the grounds ensures a smooth and enjoyable brewing experience. The ideal temperature range for this process is between 200 and 250 degrees (80-110°F), ensuring a consistent flavor and a long-lasting caffeine benefit.<|im_end|>\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "print(generate(fine_tuned_model, tokenizer, \"Tell me how to make coffee with a Chemex coffee maker.\", max_new_tokens=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Q6sLRAYXa1",
        "outputId": "0aa7a00e-7241-49e3-97e5-1f4da072bb09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are an AI assistant that helps people find information. User will you give you a question. Your task is to answer as faithfully as you can. While answering think step-by-step and justify your answer.<|im_end|>\n",
            "<|im_start|>user\n",
            "Tell me which ingredients I should use to make a Margarita drink.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "To make a Margarita drink, follow these steps:\n",
            "\n",
            "1. Preparing the margaritas: Start with a medium-sized margarita (about 4 ounces) of any type of beer or cachaucas. You can also make margaritas with other drinks like soda, salsa, or even water.\n",
            "\n",
            "2. Mixing the margaritas: Pour 1/4 cup (21.3 mm) of each margarita into a glass. This will serve two purposes: it will be easier for you to mix the margaritas while having a margarita, and it will keep the margaritas from getting too cold.\n",
            "\n",
            "3. Garnishing the margarita: Place the margarita in a large margarita glass, and fill it with ice. Garnish with a small amount of lime juice if desired.\n",
            "\n",
            "4. Serving the margarita: Serve the margarita with ice and lime juice, if desired.\n",
            "\n",
            "In this example, we'll use a medium-sized margarita called a \"cachauca\" and we'll mix it with 2 cups (56 fl oz) of beer. The margarita should fit easily into a standard cocktail glass without being too heavy or thick.\n",
            "\n",
            "Justification:\n",
            "\n",
            "We started by mixing the margaritas separately before pouring them together. This way, we could have different margaritas at once, making it easier to mix them properly. Then, we filled the glasses with ice and lime juice according to our preference.\n",
            "\n",
            "So, if we want to make a Margarita drink with margarita, we should mix the margaritas separately and then pour them into individual glasses.<|im_end|>\n",
            "<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "print(generate(fine_tuned_model, tokenizer, \"Tell me which ingredients I should use to make a Margarita drink.\", max_new_tokens=500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULsU8tXWB7gY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "4. instruction tuning olmo on a single GPU",
      "widgets": {}
    },
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0130970e878f48fba3bf4e361ee9883e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b37e205f194345991a759b50c7b6df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "054c4d2d30bf4055bc0fa71f08b23377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063c222cfc944ea2946a27479669e8cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5f283c540243e685a8c4d5499ca931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ad75440da64e99b2f053c8168cf8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3c330124684ed7be73e0020ec28db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab12622fc594f3d995f22e362b9b212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d7c9cd742349dc9d7d3f6f0b13c224",
            "max": 363491,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e8503f954b4c4c8861401d80b022bf",
            "value": 363491
          }
        },
        "2adce43ac4bc47a88f03d4d84e469aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d4b356373d40e78e81131367a01e72",
            "placeholder": "​",
            "style": "IPY_MODEL_2f986cd5c1d64ba788eeef3653fcbef0",
            "value": " 363491/363491 [00:03&lt;00:00, 134241.86 examples/s]"
          }
        },
        "2ead0736c1794e588e0dc54f1aa1b02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ad75440da64e99b2f053c8168cf8b5",
            "placeholder": "​",
            "style": "IPY_MODEL_dbcf08370a6647fe9838927c6cb3f3ad",
            "value": "Generating train split: 100%"
          }
        },
        "2f986cd5c1d64ba788eeef3653fcbef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "336ab53cd34e48f3b6e934cfac4cd1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063c222cfc944ea2946a27479669e8cc",
            "placeholder": "​",
            "style": "IPY_MODEL_d9f1a0c5761548b4a2d542d3b981b8ac",
            "value": "dataset_infos.json: 100%"
          }
        },
        "3aeb1159631249bf9fa76439e7f8808a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f010f62faed4d03b5617f540f216aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a1c38eadea4f95a0e2a49b5c0d4825": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_593e04a22b3c4b5eb772211948b14c66",
            "placeholder": "​",
            "style": "IPY_MODEL_b8e896879377470287d0cb410959511b",
            "value": "(…)-00001-of-00002-20da825e60baa022.parquet: 100%"
          }
        },
        "42d7c9cd742349dc9d7d3f6f0b13c224": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "436ead45746b422c864dc6b70b224b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4e13b79919d41d2b8ac4a2cddc191e8",
              "IPY_MODEL_966f01d289fb4842bf94e5019b095dfa",
              "IPY_MODEL_773c73bfb5d644448b069ee04ec4df52"
            ],
            "layout": "IPY_MODEL_8bb05a19de9c4a91903efb37e00aaa2d"
          }
        },
        "46e63ff18e0f42a59cf01f23bf22ce0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73684289388743c292cf1f536641fb89",
              "IPY_MODEL_81e468bf13c64391a748b112691936f5",
              "IPY_MODEL_8f74e472c7bc4382b813f7c4d2444a40"
            ],
            "layout": "IPY_MODEL_0130970e878f48fba3bf4e361ee9883e"
          }
        },
        "47976a62313842309661edc78b8716a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ebaaffbe04049b59d947a75f2d1084c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ffb2f3d29e48d386655dd0bf09ed08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5f283c540243e685a8c4d5499ca931",
            "placeholder": "​",
            "style": "IPY_MODEL_054c4d2d30bf4055bc0fa71f08b23377",
            "value": " 145M/145M [00:06&lt;00:00, 22.8MB/s]"
          }
        },
        "593e04a22b3c4b5eb772211948b14c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4bc915efe44678be50432007d9c6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04030dc8c9d49959e8e5631edfc6d5f",
            "max": 2939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4c97278aac84263abecbe0ce5dfeeff",
            "value": 2939
          }
        },
        "61ecf95f0d2446eeb33efd65a85ae5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48bef9d985d40ce82769813b9621aa1",
            "max": 144668970,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c30e74a63cbe4f97b079a3879ad9ab73",
            "value": 144668970
          }
        },
        "65ff521eba10495692b41f085ec33fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_336ab53cd34e48f3b6e934cfac4cd1c8",
              "IPY_MODEL_7e2a7b9468254fe1ae49557fe2726b79",
              "IPY_MODEL_6e7256e81ffe491da8ea45bd10987702"
            ],
            "layout": "IPY_MODEL_94d990a792fb47b995b16a67a32c526e"
          }
        },
        "68e8503f954b4c4c8861401d80b022bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dab287bf20c4b0e9d36bd3a5aaec195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7256e81ffe491da8ea45bd10987702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b36601341dfa495aaa0217115d00aeab",
            "placeholder": "​",
            "style": "IPY_MODEL_73552c210a6f4b01a10fbd666a3ce60f",
            "value": " 653/653 [00:00&lt;00:00, 44.4kB/s]"
          }
        },
        "73552c210a6f4b01a10fbd666a3ce60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73684289388743c292cf1f536641fb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f010f62faed4d03b5617f540f216aeb",
            "placeholder": "​",
            "style": "IPY_MODEL_d187b4ed87e54d6981ded5e64ad2caf1",
            "value": "Map (num_proc=16): 100%"
          }
        },
        "773c73bfb5d644448b069ee04ec4df52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aeb1159631249bf9fa76439e7f8808a",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3c330124684ed7be73e0020ec28db4",
            "value": " 163M/163M [00:06&lt;00:00, 24.2MB/s]"
          }
        },
        "77e6fa69d6734bb9be4924fefe829a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "793cb4504eb149f5ba6103bf29e582de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f69d3343f97f4def9be945519391c445",
            "placeholder": "​",
            "style": "IPY_MODEL_c10c10979eb74a6387b035e8ffcbd030",
            "value": "README.md: 100%"
          }
        },
        "7bc24f4a197e401c846e507239629fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ead0736c1794e588e0dc54f1aa1b02e",
              "IPY_MODEL_2ab12622fc594f3d995f22e362b9b212",
              "IPY_MODEL_2adce43ac4bc47a88f03d4d84e469aa9"
            ],
            "layout": "IPY_MODEL_a0d1d1a655944cd7b18372acf023144f"
          }
        },
        "7e2a7b9468254fe1ae49557fe2726b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82e93bf1ad3e45d692d45f25bfd2f0f9",
            "max": 653,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47976a62313842309661edc78b8716a9",
            "value": 653
          }
        },
        "81e468bf13c64391a748b112691936f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c344e31557f4d688fcfcbfb58790457",
            "max": 11000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf91255f75441cbb3586ebaadcf3017",
            "value": 11000
          }
        },
        "824a00aa352f4541b162e647943734d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e93bf1ad3e45d692d45f25bfd2f0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb05a19de9c4a91903efb37e00aaa2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c344e31557f4d688fcfcbfb58790457": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f74e472c7bc4382b813f7c4d2444a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77e6fa69d6734bb9be4924fefe829a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_caf4d30296a84cacac5432ee72f41013",
            "value": " 11000/11000 [00:25&lt;00:00, 115.11 examples/s]"
          }
        },
        "93d4b356373d40e78e81131367a01e72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94d990a792fb47b995b16a67a32c526e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "966f01d289fb4842bf94e5019b095dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebaaffbe04049b59d947a75f2d1084c",
            "max": 162644821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7e2bd696464a818a0a7d53bc67254e",
            "value": 162644821
          }
        },
        "96967d9ec45941bfaf1d22bac18b2ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04030dc8c9d49959e8e5631edfc6d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d1d1a655944cd7b18372acf023144f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2185edc9b614af786f81d4efd11d878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_793cb4504eb149f5ba6103bf29e582de",
              "IPY_MODEL_5c4bc915efe44678be50432007d9c6ad",
              "IPY_MODEL_e34f9e0457b04293a84cf6b9563e9345"
            ],
            "layout": "IPY_MODEL_feceed7c3f57463dacf2858174a35cc4"
          }
        },
        "aaf91255f75441cbb3586ebaadcf3017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b36601341dfa495aaa0217115d00aeab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e13b79919d41d2b8ac4a2cddc191e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01b37e205f194345991a759b50c7b6df",
            "placeholder": "​",
            "style": "IPY_MODEL_6dab287bf20c4b0e9d36bd3a5aaec195",
            "value": "(…)-00000-of-00002-6d275f30fa8e143f.parquet: 100%"
          }
        },
        "b8e896879377470287d0cb410959511b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf7e2bd696464a818a0a7d53bc67254e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c10c10979eb74a6387b035e8ffcbd030": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30e74a63cbe4f97b079a3879ad9ab73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c33baee068cd4ff0b521223bf4f4d404": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c48bef9d985d40ce82769813b9621aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caf4d30296a84cacac5432ee72f41013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d187b4ed87e54d6981ded5e64ad2caf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4c97278aac84263abecbe0ce5dfeeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9f1a0c5761548b4a2d542d3b981b8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbcf08370a6647fe9838927c6cb3f3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e34f9e0457b04293a84cf6b9563e9345": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96967d9ec45941bfaf1d22bac18b2ef2",
            "placeholder": "​",
            "style": "IPY_MODEL_c33baee068cd4ff0b521223bf4f4d404",
            "value": " 2.94k/2.94k [00:00&lt;00:00, 196kB/s]"
          }
        },
        "ee0a5f1a5b41412daca5c717935ecaea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41a1c38eadea4f95a0e2a49b5c0d4825",
              "IPY_MODEL_61ecf95f0d2446eeb33efd65a85ae5af",
              "IPY_MODEL_52ffb2f3d29e48d386655dd0bf09ed08"
            ],
            "layout": "IPY_MODEL_824a00aa352f4541b162e647943734d3"
          }
        },
        "f69d3343f97f4def9be945519391c445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feceed7c3f57463dacf2858174a35cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}